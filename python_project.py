# -*- coding: utf-8 -*-
"""PYTHON  PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fgQE8sRR5T-9Tqwl0VRkMwY_k3vDxdnS
"""

from google.colab import files
uploaded = files.upload()

import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    confusion_matrix
)

import joblib

# -----------------------------
# Global constants
# -----------------------------
DATA_FILE = "telecom_churn_dataset_current_operator.csv"
OUR_OPERATOR_NAME = "OurTel"
ENRICHED_OURTEL_FILE = "telecom_churn_with_scores_ourtel.csv"
BEST_MODEL_FILE = "best_churn_model.pkl"


# -----------------------------
# 1Ô∏è‚É£ EDA
# -----------------------------
def plot_histogram(df, column, bins=30):
    plt.figure(figsize=(6, 4))
    plt.hist(df[column].dropna(), bins=bins, edgecolor="black")
    plt.title(f"Histogram of {column}")
    plt.xlabel(column)
    plt.ylabel("Frequency")
    plt.tight_layout()
    plt.show()
    plt.close()


def plot_correlation_heatmap(df):
    numeric_df = df.select_dtypes(include=[np.number])
    if numeric_df.empty:
        print("No numeric columns for correlation heatmap.")
        return

    corr_matrix = numeric_df.corr()

    plt.figure(figsize=(10, 8))
    im = plt.imshow(corr_matrix, interpolation="nearest", aspect="auto")
    plt.title("Correlation Heatmap")
    plt.colorbar(im, fraction=0.046, pad=0.04)

    ticks = np.arange(len(corr_matrix.columns))
    plt.xticks(ticks, corr_matrix.columns, rotation=90)
    plt.yticks(ticks, corr_matrix.columns)

    plt.tight_layout()
    plt.show()
    plt.close()


def run_eda(df):
    print("===== BASIC INFO =====")
    print("Shape:", df.shape)
    print("\nHead:")
    print(df.head())
    print("\nInfo:")
    df.info()
    print("\nDescribe:")
    print(df.describe())

    if "churn" in df.columns:
        print("\nOverall churn rate:", df["churn"].mean())
    else:
        print("'churn' column not found.")
        return

    if "region" in df.columns:
        print("\nChurn by region:")
        print(df.groupby("region")["churn"].mean())

    if "current_operator" in df.columns:
        print("\nChurn by current operator:")
        print(df.groupby("current_operator")["churn"].mean())

    if "plan_type" in df.columns and "plan_category" in df.columns:
        print("\nChurn by plan type & category:")
        print(df.groupby(["plan_type", "plan_category"])["churn"].mean())

    if "region" in df.columns and "current_operator" in df.columns:
        print("\nChurn by region & operator:")
        table = (
            df.groupby(["region", "current_operator"])["churn"]
            .mean()
            .unstack()
        )
        print(table)

    hist_cols = [
        "tenure_months",
        "monthly_charge",
        "call_drops",
        "network_issues",
        "dissatisfaction_score",
    ]
    for col in hist_cols:
        if col in df.columns:
            plot_histogram(df, col)

    plot_correlation_heatmap(df)


# -----------------------------
# 2Ô∏è‚É£ MODEL TRAINING
# -----------------------------
def build_preprocessor(X):
    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()

    numeric_transformer = Pipeline([
        ("scaler", StandardScaler())
    ])
    categorical_transformer = Pipeline([
        ("onehot", OneHotEncoder(handle_unknown="ignore"))
    ])

    return ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, numeric_features),
            ("cat", categorical_transformer, categorical_features),
        ]
    )


def train_and_compare_models(df_ourtel):
    df_ourtel = df_ourtel[df_ourtel["current_operator"] == OUR_OPERATOR_NAME].copy()
    X = df_ourtel.drop(columns=["customer_id", "churn", "current_operator"])
    y = df_ourtel["churn"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=42, stratify=y
    )

    preprocessor = build_preprocessor(X)

    models = {
        "LogisticRegression": LogisticRegression(max_iter=1000),
        "RandomForest": RandomForestClassifier(
            n_estimators=200, random_state=42, n_jobs=-1
        )
    }

    results = []
    fitted_models = {}

    print("\n===== MODEL TRAINING =====")

    for name, clf in models.items():
        print(f"\nTraining {name}...")
        pipe = Pipeline([("preprocessor", preprocessor), ("model", clf)])
        pipe.fit(X_train, y_train)
        fitted_models[name] = pipe

        y_pred = pipe.predict(X_test)
        y_proba = pipe.predict_proba(X_test)[:, 1]

        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        roc = roc_auc_score(y_test, y_proba)
        cm = confusion_matrix(y_test, y_pred)

        print(f"Accuracy:  {acc:.4f}")
        print(f"Precision: {prec:.4f}")
        print(f"Recall:    {rec:.4f}")
        print(f"F1-score:  {f1:.4f}")
        print(f"ROC-AUC:   {roc:.4f}")
        print("Confusion Matrix:\n", cm)

        results.append({
            "model": name,
            "accuracy": acc,
            "precision": prec,
            "recall": rec,
            "f1_score": f1,
            "roc_auc": roc
        })

    metrics_df = pd.DataFrame(results).set_index("model")
    print("\n===== MODEL COMPARISON =====")
    print(metrics_df)

    best_name = metrics_df["roc_auc"].idxmax()
    best_model = fitted_models[best_name]
    print("\nBest model:", best_name)

    joblib.dump(best_model, BEST_MODEL_FILE)
    print("Saved best model to:", BEST_MODEL_FILE)

    return best_model, metrics_df


# -----------------------------
# 3Ô∏è‚É£ SCORING + RISK
# -----------------------------
def assign_risk_segment(prob):
    if prob < 0.30:
        return "Low risk"
    elif prob <= 0.70:
        return "Grey area"
    return "High risk"


def score_and_segment(df_ourtel, best_model):
    df_ourtel = df_ourtel[df_ourtel["current_operator"] == OUR_OPERATOR_NAME].copy()

    X = df_ourtel.drop(columns=["customer_id", "churn", "current_operator"])
    probs = best_model.predict_proba(X)[:, 1]

    df_ourtel["churn_probability"] = probs
    df_ourtel["risk_segment"] = df_ourtel["churn_probability"].apply(assign_risk_segment)

    print("\nRisk segment distribution:")
    print(df_ourtel["risk_segment"].value_counts())
    print("\nRisk segment proportions:")
    print(df_ourtel["risk_segment"].value_counts(normalize=True))
    print("\nActual churn by segment:")
    print(df_ourtel.groupby("risk_segment")["churn"].mean())

    return df_ourtel


# -----------------------------
# 4Ô∏è‚É£ RETENTION ACTIONS
# -----------------------------
def retention_action(row):
    actions = []

    if row["call_drops"] >= 3:
        actions.append("Optimize network; give free voice minutes.")
    if row["network_issues"] >= 5:
        actions.append("Provide free data voucher; prioritize network fix.")
    if row["dissatisfaction_score"] >= 7:
        actions.append("Proactive support call + goodwill credit.")
    if row["monthly_charge"] >= 600 and row["tenure_months"] >= 12:
        actions.append("Offer loyalty rewards and VIP care.")
    if row["risk_segment"] == "High risk":
        actions.append("Urgent intervention by relationship manager.")
    elif row["risk_segment"] == "Grey area":
        actions.append("Send targeted app/SMS offers.")

    if not actions:
        actions.append("Maintain engagement with periodic check-ins.")

    return " ".join(actions)


def add_retention_actions(df):
    df = df.copy()
    df["retention_actions"] = df.apply(retention_action, axis=1)
    df.to_csv(ENRICHED_OURTEL_FILE, index=False)
    print("\nSaved enriched dataset to:", ENRICHED_OURTEL_FILE)
    return df


# -----------------------------
# MAIN
# -----------------------------
def main():
    print("Loading dataset:", DATA_FILE)
    df = pd.read_csv(DATA_FILE)

    print("\nRunning EDA‚Ä¶")
    run_eda(df)

    df_ourtel = df[df["current_operator"] == OUR_OPERATOR_NAME].copy()

    print("\nTraining models‚Ä¶")
    best_model, metrics = train_and_compare_models(df_ourtel)

    print("\nScoring customers‚Ä¶")
    scored = score_and_segment(df_ourtel, best_model)

    print("\nAdding retention recommendations‚Ä¶")
    enriched = add_retention_actions(scored)

    print("\nDONE!")
    print("Best model saved at:", BEST_MODEL_FILE)
    print("Enriched dataset saved at:", ENRICHED_OURTEL_FILE)


if __name__ == "__main__":
    main()

!pip install pandas plotly scikit-learn ipywidgets --quiet

import pandas as pd
import numpy as np
import plotly.express as px
from IPython.display import display
import ipywidgets as widgets

from google.colab import files

print("Upload telecom_churn_dataset_current_operator.csv")
uploaded = files.upload()

print("Upload telecom_churn_with_scores_ourtel.csv")
uploaded2 = files.upload()

FULL_DATA_FILE = "telecom_churn_dataset_current_operator.csv"
OURTEL_ENRICHED_FILE = "telecom_churn_with_scores_ourtel.csv"
OUR_OPERATOR_NAME = "OurTel"

df_full = pd.read_csv(FULL_DATA_FILE)
df_ourtel = pd.read_csv(OURTEL_ENRICHED_FILE)

# Safety filter for OurTel
df_ourtel = df_ourtel[df_ourtel["current_operator"] == OUR_OPERATOR_NAME].copy()

print("Full dataset shape:", df_full.shape)
print("OurTel enriched dataset shape:", df_ourtel.shape)

df_full.head()

def compute_kpis(df_ourtel_filtered: pd.DataFrame):
    """Compute KPI metrics for OurTel (on filtered data)."""
    total_customers = len(df_ourtel_filtered)
    churn_rate = df_ourtel_filtered["churn"].mean() if total_customers > 0 else 0.0

    seg_proportions = (
        df_ourtel_filtered["risk_segment"]
        .value_counts(normalize=True)
        if total_customers > 0 and "risk_segment" in df_ourtel_filtered.columns
        else pd.Series(dtype=float)
    )

    grey_pct = seg_proportions.get("Grey area", 0.0)
    high_pct = seg_proportions.get("High risk", 0.0)

    return total_customers, churn_rate, grey_pct, high_pct


def plot_churn_by_operator(df: pd.DataFrame):
    """Bar chart: churn rate by current operator."""
    if not {"current_operator", "churn"}.issubset(df.columns):
        print("Required columns missing for churn-by-operator chart.")
        return

    chart_df = (
        df.groupby("current_operator")["churn"]
        .mean()
        .reset_index()
        .sort_values("churn", ascending=False)
    )
    fig = px.bar(
        chart_df,
        x="current_operator",
        y="churn",
        title="Churn Rate by Operator",
        labels={"churn": "Churn Rate", "current_operator": "Operator"},
        text=(chart_df["churn"] * 100).round(2).astype(str) + "%"
    )
    fig.update_traces(textposition="outside")
    fig.update_layout(yaxis_tickformat=".0%")
    fig.show()


def table_churn_by_region_operator(df: pd.DataFrame):
    """Returns a table of churn rate by region and operator."""
    if not {"region", "current_operator", "churn"}.issubset(df.columns):
        print("Required columns missing for churn-by-region-operator table.")
        return pd.DataFrame()

    pivot = (
        df.groupby(["region", "current_operator"])["churn"]
        .mean()
        .reset_index()
        .pivot(index="region", columns="current_operator", values="churn")
        .sort_index()
    )
    return (pivot * 100).round(2)  # in %


def plot_churn_probability_hist(df_ourtel_filtered: pd.DataFrame):
    """Histogram of churn_probability for OurTel."""
    if "churn_probability" not in df_ourtel_filtered.columns:
        print("'churn_probability' column missing.")
        return

    fig = px.histogram(
        df_ourtel_filtered,
        x="churn_probability",
        nbins=30,
        title="Churn Probability Distribution (OurTel)",
    )
    fig.update_layout(xaxis_title="Churn Probability", yaxis_title="Count")
    fig.show()


def plot_risk_segment_counts(df_ourtel_filtered: pd.DataFrame):
    """Bar chart of counts by risk_segment."""
    if "risk_segment" not in df_ourtel_filtered.columns:
        print("'risk_segment' column missing.")
        return

    chart_df = (
        df_ourtel_filtered["risk_segment"]
        .value_counts()
        .reset_index()
        .rename(columns={"index": "risk_segment", "risk_segment": "count"})
    )
    fig = px.bar(
        chart_df,
        x="risk_segment",
        y="count",
        title="Customers by Risk Segment (OurTel)",
        text="count",
    )
    fig.update_traces(textposition="outside")
    fig.show()

# Build options from data
regions = sorted(df_full["region"].dropna().unique().tolist()) if "region" in df_full.columns else []
risk_segments = sorted(df_ourtel["risk_segment"].dropna().unique().tolist()) if "risk_segment" in df_ourtel.columns else []
plan_types = sorted(df_full["plan_type"].dropna().unique().tolist()) if "plan_type" in df_full.columns else []

# Widgets
region_multiselect = widgets.SelectMultiple(
    options=regions,
    value=tuple(regions),
    description='Region',
    disabled=False
)

risk_multiselect = widgets.SelectMultiple(
    options=risk_segments,
    value=tuple(risk_segments),
    description='Risk',
    disabled=False
)

plan_multiselect = widgets.SelectMultiple(
    options=plan_types,
    value=tuple(plan_types),
    description='Plan',
    disabled=False
)

display(
    widgets.HTML("<h3>üîß Filters</h3>"),
    widgets.HBox([region_multiselect, risk_multiselect, plan_multiselect])
)

def run_dashboard(regions_selected, risks_selected, plans_selected):
    # Convert widget selections (tuples) to lists
    regions_selected = list(regions_selected)
    risks_selected = list(risks_selected)
    plans_selected = list(plans_selected)

    # Filter full data
    df_full_f = df_full.copy()

    if regions_selected and "region" in df_full_f.columns:
        df_full_f = df_full_f[df_full_f["region"].isin(regions_selected)]
    if plans_selected and "plan_type" in df_full_f.columns:
        df_full_f = df_full_f[df_full_f["plan_type"].isin(plans_selected)]

    # Filter OurTel data
    df_ourtel_f = df_ourtel.copy()
    if regions_selected and "region" in df_ourtel_f.columns:
        df_ourtel_f = df_ourtel_f[df_ourtel_f["region"].isin(regions_selected)]
    if plans_selected and "plan_type" in df_ourtel_f.columns:
        df_ourtel_f = df_ourtel_f[df_ourtel_f["plan_type"].isin(plans_selected)]
    if risks_selected and "risk_segment" in df_ourtel_f.columns:
        df_ourtel_f = df_ourtel_f[df_ourtel_f["risk_segment"].isin(risks_selected)]

    display(widgets.HTML("<hr><h3>üìå OurTel KPIs (Filtered)</h3>"))
    total_cust, churn_rate, grey_pct, high_pct = compute_kpis(df_ourtel_f)
    print(f"Total OurTel Customers: {total_cust}")
    print(f"OurTel Churn Rate: {churn_rate:.2%}")
    print(f"Grey Area Customers: {grey_pct:.2%}")
    print(f"High Risk Customers: {high_pct:.2%}")

    # Benchmark table
    display(widgets.HTML("<h3>üìä Churn Rate by Region & Operator (%, Filtered)</h3>"))
    benchmark_table = table_churn_by_region_operator(df_full_f)
    display(benchmark_table)

    # Churn by operator
    display(widgets.HTML("<h3>üìâ Churn Rate by Operator (Bar Chart)</h3>"))
    plot_churn_by_operator(df_full_f)

    # OurTel risk & actions
    display(widgets.HTML("<h3>üî• OurTel Risk Segmentation</h3>"))
    plot_churn_probability_hist(df_ourtel_f)
    plot_risk_segment_counts(df_ourtel_f)

    # Top risk customers
    display(widgets.HTML("<h3>üö® Top Grey/High Risk OurTel Customers (Filtered)</h3>"))
    if "risk_segment" in df_ourtel_f.columns and "churn_probability" in df_ourtel_f.columns:
        high_grey = df_ourtel_f[df_ourtel_f["risk_segment"].isin(["Grey area", "High risk"])].copy()
        high_grey = high_grey.sort_values("churn_probability", ascending=False)

        cols_to_show = [
            "customer_id",
            "region",
            "plan_type",
            "plan_category",
            "monthly_charge",
            "dissatisfaction_score",
            "churn_probability",
            "risk_segment",
            "retention_actions",
        ]
        cols_to_show = [c for c in cols_to_show if c in high_grey.columns]

        display(high_grey[cols_to_show].head(100))
    else:
        print("Required columns missing for top risk customers table.")

out = widgets.interactive_output(
    run_dashboard,
    {
        "regions_selected": region_multiselect,
        "risks_selected": risk_multiselect,
        "plans_selected": plan_multiselect,
    }
)

display(out)